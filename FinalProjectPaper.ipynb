{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0c2a0c-81ae-40ae-a91f-15f0ee54d8ca",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Dark patterns are deceptive elements that are intentionally made to make users do actions they would not otherwise. This technique is used to benefit various stakeholders through web products, social media, popular apps or web services. With UX and HCI rapidly expanding this technique is revealing various ethical issues, and creating an umbrella term of dark patterns. Dark patterns are becoming more aware and acknowledged in the UX and HCI community, but users are still falling for Dark Patterns.  Dark patterns are specifically interesting because of the way they are designed, they are designed with intent to make the user mess up or worded differently to try to trick the user. There’s a certain art to making a Dark Pattern, but many users can’t identify Dark Patterns. It might not look inherently bad but there was intent behind it. Which leads to my interest in trying to understand the severity of deceptiveness, but also how aware are users and are they able to identify Dark Patterns. \n",
    "\n",
    "This topic is important to explore to understand the effects Dark Patterns have on users, but also understand the serverity of the deception. Dark Patterns are inherently bad, but the scale/level of bad ranges. It has the effects of coercing, steering, or deceiving users to make unintended or potentially harmful decisions which makes it an ethical concern and is important for us to understand the sererity and the design of dark patterns. Now design is being weaponized using behavioral research to serve and aim economical goals. The emerging trends of dark patterns risk users autonomy. \n",
    "\n",
    "# Related Work\n",
    "Dark Patterns are made well aware in the UX community, but has more recently been a hot topic in academic journals. There are a couple articles and one data set that is publicly available, the articles that are available that I found and read have been written within the last 3 years. The articles I found discussed the Dark Patterns found on web services and looked into shopping experiences more deeply. With Dark Patterns becoming more of a hot topic there have been more academic journals published within the last year. The concept of Dark Patterns is still a relatively new concept, it came into light around 2010 by a London UX Designer Dr. Harry Brignull. The articles/journals I read examined the characteristics Dark Patterns have and the different types of on web services, some journals explored the ethical concerns and impacts . They were able to examine different Dark Patterns by conducting research by searching and finding the dark pattern throughout the web, and identifying different defining characteristics like nudging , growth hacking, zuckerberging, and scarcity.  The main goals of the articles I read were to expand and broaden the knowledge around Dark Patterns, but also understand the limitations, deceptiveness, and the future of the technique.  A lot of the articles dove deeper into the umbrella terms of Dark Patterns, identifying the main Dark Patterns they saw and what they are/how they work. \n",
    "\n",
    "### Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites \n",
    "This is the main data set I used along the article/research to get context. This paper was accepted at ACM CSCW 2019, they used automated techniques to identify dark patterns on a large data set of websites.  They used Princeton Web Census Crawl to find 11K Shopping Websites to study the websites and understand how often dark patterns influence users to purchase more. They analyzed around 53K product pages from 11K websites, and found 1,818 dark patterns representing 15 different types and 7 categories. The data set has the string of commentary from the website and the type of comment. The data set also has the dark pattern type organized, pattern type, where it was on the website, and whether it was deceptive or not. \n",
    "https://webtransparency.cs.princeton.edu/dark-patterns/\n",
    "\n",
    "#### Method\n",
    "The method that this article used relied on automating the primary interaction path of websites, and extracting textual interface elements then grouping and organizing. They designed a Web Crawler capable to navigate users primary interactions, the web crawler imitated how the user would use the website and purchase items. They retried a list of popular websites from Alexa using Top Sites API, data collected with a website crawl to train logistic regression classifier, then data analysis. \n",
    "\n",
    "This method seems appropriate and good to use, it makes the data collection a lot quicker and easier to grab big amounts of data. The Web Crawler was super interesting to read about and learn about, how it was able to replicate users' mental model and use of websites to gather dark pattern characteristics and patterns. I’m sure there were some limitations when training the logistic regression, but overall it seems to be an effective way to look through a lot of websites and gather information/data on dark patterns. \n",
    "\n",
    "#### License/Terms of Use\n",
    "###### Background\n",
    "Since 2015, we have conducted a web census to study third-party online tracking. Each month, our bot visits the web’s 1 million most popular sites and records data pertaining to user privacy, including cookies, fingerprinting scripts, the effect of browser privacy tools, and the exchange of tracking data between different sites (\"cookie syncing\").\n",
    "\n",
    "Our open-source measurement software, OpenWPM, has been used in dozens of other studies. In 2016 we published a paper \"Online Tracking: A 1-million-site Measurement and Analysis\" based on a snapshot of this data, and released that snapshot.\n",
    "\n",
    "Now we are releasing the entire Princeton Web Census data -- about 15 terabytes -- containing privacy measurements of 1 million sites conducted each month from December 2015 to June 2018.\n",
    "\n",
    "We plan to run one or two more crawls in the next few months (until mid 2019), and we will update this data release periodically. (Update: November 2018 and June 2019 crawls are added to the release.)\n",
    "\n",
    "###### Access\n",
    "Send an email to web-census-data@lists.cs.princeton.edu to request access to the dataset. Please tell us who you are and a high-level description of what you plan to use it for. (We'll approve all requests, but we'd like to get an idea of how people are using the data.)\n",
    "\n",
    "###### Overview of the data\n",
    "Each month, we run measurements in eight configurations at scales ranging from 10,000 sites to 1 million sites, summarized here. Please visits dataset details page for usage information, timeline of changes and issues with the data.\n",
    "https://webtransparency.cs.princeton.edu/webcensus/data-release/\n",
    " \n",
    "### UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception (CHI2020)\n",
    "This data set was public but could not be accessed well, I could only look at the data set and not interact with it. So I used the data set for more of a reference and additional data. Some of the data set organization was unclear and unknown due to the fact that the article corresponding to the data was not published yet to the public. But it did come with a website and the CHI2020 Video presentation that gave a brief finding report and brief article abstract. This data set classified 240 trending Google Free Applications, two researchers manually inspected and then a third. They found that 95% of the 240 apps had one or more dark patterns. They even had users look through and try to identify the dark pattern and 55% of the users could not spot it and 20% were unsure. From the synopsis the main goal of this was to understand and identify dark patterns and the relevancy, as well as if users can acknowledge/see the dark patterns. There wasn't a licensing available yet. \n",
    "https://lindig11.github.io/ldg/dp.html\n",
    "\n",
    "https://figshare.com/s/048c984854a59429d0f0\n",
    "\n",
    "Interesting article call out, this was explored more on ethics but also the future of dark patterns. This article was a little different compared to the other ones, but not by much. https://www.researchgate.net/publication/322916969_The_Dark_Patterns_Side_of_UX_Design\n",
    "\n",
    "#### Other articles/Resources: \n",
    "https://cacm.acm.org/magazines/2020/9/246937-dark-patterns/fulltext (Talks about past,future, present)\n",
    "https://www.researchgate.net/publication/341105338_DARK_PATTERNS_IN_THE_MEDIA_A_SYSTEMATIC_REVIEW\n",
    "https://computerscience.uchicago.edu/news/article/dark-patterns/ (Online shopping)\n",
    "https://dl.acm.org/doi/10.1145/3313831.3376600\n",
    "https://themarkup.org/2021/06/03/dark-patterns-that-mislead-consumers-are-all-over-the-internet\n",
    "https://www.darkpatterns.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a51563-2498-4cf5-be70-c06149605ba8",
   "metadata": {},
   "source": [
    "# Hypothese/Research Question \n",
    "I want to understand the range and severity of dark patterns deceptiveness.  My research question is how to range them from low, med, and high severity and understand the grey area and differentiate between the ranges/ranking. I feel like there still is a grey area of what’s deceptive and inherently bad since not all dark patterns are really bad. I’m also curious to understand the correlation between deceptiveness and users' knowledge of spotting/identifying dark patterns.  I want to understand hat makes dark patterns deceptive, and what's the severity level of dark patterns?\n",
    "\n",
    "Clarifying the term of deception is and the ranking, overall deception in this case is deceiving the user and the intentions they have on the webpage. Lowstakes deception would be getting the user off task/rerouting them, medium would be a white lie or provoking the user sale/shipping, and high would be a higher stakes lie or no alternative way out/forced response or action taking place. The term could change or alter a bit. \n",
    "\n",
    "# Methodology \n",
    "In terms of my methdology for this project I decided to look at the Website Crawl dataset, and go through scanning and understanding the data set. As well as cleaning the data set, I'm choosing to focus on the deceptive column of data, the pattern string, and type. I also ran the data set on R Studio (Screenshot), where I read the csv file and did a summary of the data. This gave me a quick synopsis of the data I have to understand what I'm working with and gave me a basis to start this project. It also helped me expand my research question, by questioning the deception of dark patterns and how it plays a role in the characteristics of dark patterns. \n",
    "My results: file:///Users/britnie/Downloads/SOC225_HW1_Chin%20(1).html \n",
    "# Findings \n",
    "\n",
    "# Discussions \n",
    "\n",
    "# Conclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cab19b-04aa-44e8-80fa-de6f7ef902e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
