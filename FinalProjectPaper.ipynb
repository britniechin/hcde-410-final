{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d0c2a0c-81ae-40ae-a91f-15f0ee54d8ca",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Dark patterns are deceptive elements that are intentionally made to make users do actions they would not otherwise. This technique is used to benefit various stakeholders through web products, social media, popular apps or web services. With UX and HCI rapidly expanding this technique is revealing various ethical issues, and creating an umbrella term of dark patterns. Dark patterns are becoming more aware and acknowledged in the UX and HCI community, but users are still falling for Dark Patterns.  Dark patterns are specifically interesting because of the way they are designed, they are designed with intent to make the user mess up or worded differently to try to trick the user. There’s a certain art to making a Dark Pattern, but many users can’t identify Dark Patterns. It might not look inherently bad but there was intent behind it. Which leads to my interest in trying to understand the severity of deceptiveness, but also how aware are users and are they able to identify Dark Patterns. \n",
    "\n",
    "This topic is important to explore to understand the effects Dark Patterns have on users, but also understand the serverity of the deception. Dark Patterns are inherently bad, but the scale/level of bad ranges. It has the effects of coercing, steering, or deceiving users to make unintended or potentially harmful decisions which makes it an ethical concern and is important for us to understand the sererity and the design of dark patterns. Now design is being weaponized using behavioral research to serve and aim economical goals. The emerging trends of dark patterns risk users autonomy. \n",
    "\n",
    "# Related Work\n",
    "Dark Patterns are made well aware in the UX community, but has more recently been a hot topic in academic journals. There are a couple articles and one data set that is publicly available, the articles that are available that I found and read have been written within the last 3 years. The articles I found discussed the Dark Patterns found on web services and looked into shopping experiences more deeply. With Dark Patterns becoming more of a hot topic there have been more academic journals published within the last year. The concept of Dark Patterns is still a relatively new concept, it came into light around 2010 by a London UX Designer Dr. Harry Brignull. The articles/journals I read examined the characteristics Dark Patterns have and the different types of on web services, some journals explored the ethical concerns and impacts . They were able to examine different Dark Patterns by conducting research by searching and finding the dark pattern throughout the web, and identifying different defining characteristics like nudging , growth hacking, zuckerberging, and scarcity.  The main goals of the articles I read were to expand and broaden the knowledge around Dark Patterns, but also understand the limitations, deceptiveness, and the future of the technique.  A lot of the articles dove deeper into the umbrella terms of Dark Patterns, identifying the main Dark Patterns they saw and what they are/how they work. \n",
    "\n",
    "### Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites \n",
    "This is the main data set I used along the article/research to get context. This paper was accepted at ACM CSCW 2019, they used automated techniques to identify dark patterns on a large data set of websites.  They used Princeton Web Census Crawl to find 11K Shopping Websites to study the websites and understand how often dark patterns influence users to purchase more. They analyzed around 53K product pages from 11K websites, and found 1,818 dark patterns representing 15 different types and 7 categories. The data set has the string of commentary from the website and the type of comment. The data set also has the dark pattern type organized, pattern type, where it was on the website, and whether it was deceptive or not. \n",
    "https://webtransparency.cs.princeton.edu/dark-patterns/\n",
    "\n",
    "#### Method\n",
    "The method that this article used relied on automating the primary interaction path of websites, and extracting textual interface elements then grouping and organizing. They designed a Web Crawler capable to navigate users primary interactions, the web crawler imitated how the user would use the website and purchase items. They retried a list of popular websites from Alexa using Top Sites API, data collected with a website crawl to train logistic regression classifier, then data analysis. \n",
    "\n",
    "This method seems appropriate and good to use, it makes the data collection a lot quicker and easier to grab big amounts of data. The Web Crawler was super interesting to read about and learn about, how it was able to replicate users' mental model and use of websites to gather dark pattern characteristics and patterns. I’m sure there were some limitations when training the logistic regression, but overall it seems to be an effective way to look through a lot of websites and gather information/data on dark patterns. \n",
    "\n",
    "#### License/Terms of Use\n",
    "###### Background\n",
    "Since 2015, we have conducted a web census to study third-party online tracking. Each month, our bot visits the web’s 1 million most popular sites and records data pertaining to user privacy, including cookies, fingerprinting scripts, the effect of browser privacy tools, and the exchange of tracking data between different sites (\"cookie syncing\").\n",
    "\n",
    "Our open-source measurement software, OpenWPM, has been used in dozens of other studies. In 2016 we published a paper \"Online Tracking: A 1-million-site Measurement and Analysis\" based on a snapshot of this data, and released that snapshot.\n",
    "\n",
    "Now we are releasing the entire Princeton Web Census data -- about 15 terabytes -- containing privacy measurements of 1 million sites conducted each month from December 2015 to June 2018.\n",
    "\n",
    "We plan to run one or two more crawls in the next few months (until mid 2019), and we will update this data release periodically. (Update: November 2018 and June 2019 crawls are added to the release.)\n",
    "\n",
    "###### Access\n",
    "Send an email to web-census-data@lists.cs.princeton.edu to request access to the dataset. Please tell us who you are and a high-level description of what you plan to use it for. (We'll approve all requests, but we'd like to get an idea of how people are using the data.)\n",
    "\n",
    "###### Overview of the data\n",
    "Each month, we run measurements in eight configurations at scales ranging from 10,000 sites to 1 million sites, summarized here. Please visits dataset details page for usage information, timeline of changes and issues with the data.\n",
    "https://webtransparency.cs.princeton.edu/webcensus/data-release/\n",
    " \n",
    "### UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception (CHI2020)\n",
    "This data set was public but could not be accessed well, I could only look at the data set and not interact with it. So I used the data set for more of a reference and additional data. Some of the data set organization was unclear and unknown due to the fact that the article corresponding to the data was not published yet to the public. But it did come with a website and the CHI2020 Video presentation that gave a brief finding report and brief article abstract. This data set classified 240 trending Google Free Applications, two researchers manually inspected and then a third. They found that 95% of the 240 apps had one or more dark patterns. They even had users look through and try to identify the dark pattern and 55% of the users could not spot it and 20% were unsure. From the synopsis the main goal of this was to understand and identify dark patterns and the relevancy, as well as if users can acknowledge/see the dark patterns. There wasn't a licensing available yet. \n",
    "https://lindig11.github.io/ldg/dp.html\n",
    "\n",
    "https://figshare.com/s/048c984854a59429d0f0\n",
    "\n",
    "Interesting article call out, this was explored more on ethics but also the future of dark patterns. This article was a little different compared to the other ones, but not by much. https://www.researchgate.net/publication/322916969_The_Dark_Patterns_Side_of_UX_Design\n",
    "\n",
    "#### Other articles/Resources: \n",
    "https://cacm.acm.org/magazines/2020/9/246937-dark-patterns/fulltext (Talks about past,future, present)\n",
    "https://www.researchgate.net/publication/341105338_DARK_PATTERNS_IN_THE_MEDIA_A_SYSTEMATIC_REVIEW\n",
    "https://computerscience.uchicago.edu/news/article/dark-patterns/ (Online shopping)\n",
    "https://dl.acm.org/doi/10.1145/3313831.3376600\n",
    "https://themarkup.org/2021/06/03/dark-patterns-that-mislead-consumers-are-all-over-the-internet\n",
    "https://www.darkpatterns.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a51563-2498-4cf5-be70-c06149605ba8",
   "metadata": {},
   "source": [
    "# Hypothese/Research Question \n",
    "I want to understand the range and severity of dark patterns deceptiveness.  My research question is how to range them from low, med, and high severity and understand the grey area and differentiate between the ranges/ranking. I feel like there still is a grey area of what’s deceptive and inherently bad since not all dark patterns are really bad. I’m also curious to understand the correlation between deceptiveness and users' knowledge of spotting/identifying dark patterns.  I want to understand hat makes dark patterns deceptive, and what's the severity level of dark patterns?\n",
    "\n",
    "Clarifying the term of deception is and the ranking, overall deception in this case is deceiving the user and the intentions they have on the webpage. Lowstakes deception would be getting the user off task/rerouting them, medium would be a white lie or provoking the user sale/shipping, and high would be a higher stakes lie or no alternative way out/forced response or action taking place. The term could change or alter a bit. \n",
    "\n",
    "I think a higher deceptiveness will be something that's hard to get out of, whereas a low will be something to convince you to buy the item. The difference will be the stakes and amount of persuading. \n",
    "\n",
    "# Methodology \n",
    "In terms of my methdology for this project I decided to look at the Website Crawl dataset, and go through scanning and understanding the data set. As well as cleaning the data set, I'm choosing to focus on the deceptive column of data, the pattern string, and type. I also ran the data set on R Studio (Screenshot), where I read the csv file and did a summary of the data. This gave me a quick synopsis of the data I have to understand what I'm working with and gave me a basis to start this project. It also helped me expand my research question, by questioning the deception of dark patterns and how it plays a role in the characteristics of dark patterns. \n",
    "My results: file:///Users/britnie/Downloads/SOC225_HW1_Chin%20(1).html \n",
    "# Findings \n",
    "For my findings the code is in the dataanalysis file. I looked at the deception rate and the category to understand what's more likely to be deceptive. To my surprise a lot of the categories were not considered deceptive which makes it a little hard to understand the differences between deceptive and non deceptive, and what makes one go the other way. I found that Urgency was the most deceptive and would be considered a high level severity, and sneaking was dependent on the situation for the data set it was categorized as depends. From my analysis Urgency, Social Proof, Misdirection, and Scarcity have the most deception. If I had to rank from low, high, med severity I would put it like this \n",
    " \n",
    "Low: Obstruction and Forced Action \n",
    "Med: Misdirection, Scarcity, and Sneaking \n",
    "High: Social Proof and Urgency \n",
    "Although I did a lot of this analysis, looking at the actual data makes it easier to represent the finding. I think there is a lot of grey area in terms of figuring out what Pattern String fits with that Pattern Category, a lot of it seems to blend it. From my own standpoint and reading through the data I wouldn’t focus on category but instead string, in my opinion these are the characteristics to define low, med, and high severity of deceptiveness. \n",
    " \n",
    "Low: Misdirection - Confirmshaming \n",
    "Med: Scarcity, Commentary/Testimonial/”name” is buying now, White Lies, Forced Action\n",
    "High: Misdirection “Congratulations”/PROMO, Forced/No Exit, \n",
    "\n",
    "\n",
    "# Discussions/Conclusion \n",
    "After doing the data analysis it was not easy to set the range of low, med, and high severity. I think a lot of it blurs and it’s hard to give a straight answer. I think a lot of this is situational. But I do think the ones that are high are being forced into a situation and not getting out. Medium being tricky design/text or guilt, and low being design that you can get out of easily but options are confusing. The overall scale is hard and it’s hard to identify the dark patterns because some of them are widely different. I think this topic is still hot and new where we’re still trying to figure out the characteristics that groping them into severity gets a little grey. \n",
    "\n",
    "Some limitations that I encountered is not having more than one public set to compare and get a deeper understanding. Although there was another one it was still considered private and I couldn’t access it fully but only really look at the data to help me understand it in more depth. Not only that, but a lot of the academic literature out there is roughly the same, they explore the different types of dark patterns they encountered.  Although they did give me a basis and good understanding there still are a lot of unknowns. \n",
    "\n",
    "For future research I think it would be interesting to understand a scale for dark patterns and also begin to identify new dark patterns. This topic is relatively new and we’re still exploring the topic, but also as design and technology advance so will dark patterns.  I also think it would be interesting to understand how users perceive dark patterns and how they work for users. I think it was interesting how one of the articles went into depth of if users could identify dark patterns. But this also becomes interesting because can we really identify dark patterns better than users. Thinking about the data set only a fraction of them were considered deceiving. How do we know based on the researchers' knowledge that they were actually deceiving or non deceiving and not the other way around. I think there needs to be more research on that and understanding mental models to identify dark patterns. I think there definitely is a range of severity in terms of deceiving, so it would be interesting to get further research. Also understanding future implications of dark patterns would be interesting as well to get into. I still think there’s a lot of grey area and a lot of the categories sort of blend together, which makes dark patterns in my opinion still a grey topic. \n",
    "On a business standpoint dark patterns are effective and it seems like a lot of the same places are using the same techniques of dark patterns to be an effective website/business. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cab19b-04aa-44e8-80fa-de6f7ef902e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
